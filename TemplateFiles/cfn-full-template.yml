AWSTemplateFormatVersion: "2010-09-09"
Description: Backup terraform.state to s3
Parameters:
  SourceBucketName:
    Description: Enter Source bucket name which stores terraform state file
    Type: String
  DestinationBucketName:
    Description: Enter Destination bucket name which stores backup
    Type: String
  # LambdaCodeBucketName:
  #   Description: Enter Bucket name which contains python as zip file
  #   Type: String
  # LambdaZipFileName:
  #   Description: Enter Zip file name which contains lambda function inside bucket 'LambdaCodeBucketName'
  #   Type: String
  DestinationAccountID:
    Description: Enter Account ID from which dynamodb has to backup
    Type: String  
  TerraformStateTableName:
    Description: Enter DynamoDb Table Name which locks terraform state
    Type: String
    Default: gks-cluster-provisioner-tf-locks-dev
  BackupTableName:
    Description: "Enter Dynamodb Table Name that you want to BackUp, Comma-delimited list"
    Type: CommaDelimitedList
    Default: "gks-backend-cognito-dev-eksTable, gks-backend-cognito-dev-gkeTable, gks-backend-cognito-dev-groupInfo, gks-backend-cognito-dev-systemConfig, gks-cluster-provisioner-tf-locks-dev"
  TemplatePath:
    Type: String
    Description: Path to CloudFormation templates (relative to top level of S3Bucket parameter)
    Default: /gks-pipeline-backup/
  S3Bucket:
    Type: String
    Default: gks-cluster-provisioner-infra-assets
  Environment:
    Type: String
    AllowedValues: 
        - dev 
        - test 
        - prod  
Resources:
  ArtifactStoreBucket:
    Type: AWS::S3::Bucket
    Properties:
      VersioningConfiguration:
        Status: Enabled
  Pipeline:
    DependsOn:
      - ArtifactStoreBucket
      - CodeBuildProject
    Type: AWS::CloudFormation::Stack
    Properties:
      TemplateURL:
        Fn::Join:
          - ""
          - - https://
            - Ref: S3Bucket
            - .s3.
            - Ref: AWS::Region
            - .amazonaws.com
            - Ref: TemplatePath
            - pipeline.yml
      Parameters:
        ArtifactBucket:
          Ref: ArtifactStoreBucket        
        Environment:
          Ref: Environment 
        CodeBuildConf: !GetAtt "CodeBuildProject.Outputs.BackupPipelineBuild"           
      TimeoutInMinutes: "20"
  CodeBuildProject:    
    Type: AWS::CloudFormation::Stack
    Properties:
      TemplateURL:
        Fn::Join:
          - ""
          - - https://
            - Ref: S3Bucket
            - .s3.
            - Ref: AWS::Region
            - .amazonaws.com
            - Ref: TemplatePath
            - build.yml
      Parameters: 
        DestinationBucketName:
          Ref: DestinationBucketName
        SourceBucketName:
          Ref: SourceBucketName            
        DestinationAccountID:
          Ref: DestinationAccountID 
        TerraformStateTableName:
          Ref: TerraformStateTableName
        BackupTableName: !Join [",", !Ref BackupTableName]          
        Environment:
          Ref: Environment     

  TriggerBuildRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Path: /
      Policies:
        - PolicyName: lambda-copier
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - codepipeline:StartPipelineExecution
                Resource: '*'                  
  LambdaTriggerStartsPipeline:
    Type: AWS::Lambda::Function
    DependsOn:
      - Pipeline
    Properties:
      Description: Start starts build for a code build project
      Handler: index.handler
      Runtime: python3.7
      Role: !GetAtt "TriggerBuildRole.Arn"
      Timeout: 20
      MemorySize: 128
      Code:
        # S3Bucket: !Ref LambdaCodeBucketName
        # S3Key: !Ref LambdaZipFileName
        ZipFile: !Sub |
          import boto3
          import os

          def handler(event, context):
              client = boto3.client("codepipeline")
              response = client.start_pipeline_execution(name=os.getenv("BACKUP_PIPELINE_NAME"))
              print(f"CodePipeline Response : {response}")
      Environment:
        Variables:
          BACKUP_PIPELINE_NAME: !GetAtt "Pipeline.Outputs.PipelineName"
  ScheduledRule:
    Type: AWS::Events::Rule
    Properties:
      Description: "ScheduledRule"
      ScheduleExpression: "cron(0 2 * * ? *)"
      State: "ENABLED"      
      Targets:
        - Arn: !GetAtt LambdaTriggerStartsPipeline.Arn
          Id: "LambdaTriggerStartsPipeline"
  PermissionForEventsToInvokeLambda:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref LambdaTriggerStartsPipeline
      Action: "lambda:InvokeFunction"
      Principal: "events.amazonaws.com"
      SourceArn:
        Fn::GetAtt:
          - "ScheduledRule"
          - "Arn"

Outputs:
  PipelineURL:
    Description: CodePipeline URL
    Value: !GetAtt "Pipeline.Outputs.PipelineURL"
  PipelineName:
    Value: !GetAtt "Pipeline.Outputs.PipelineName"
  BackupPipelineBuild:
    Description: BackupPipelineBuild
    Value: !GetAtt "CodeBuildProject.Outputs.BackupPipelineBuild"
  BackupPipelineBuildURL:
    Description: BackupPipelineBuild URL
    Value: !GetAtt "CodeBuildProject.Outputs.BackupPipelineBuildURL"
